# 复杂度

## 时间复杂度

### 复杂度分析法则

1. 只关注循环执行次数**最多**的一段代码（其他可忽略）

2. 总复杂度等于量级最大的那段代码的复杂度（其他部分可忽略，如同求极限，只留最高阶）

3. 乘法法则：嵌套代码复杂度等于嵌套内外代码复杂度的乘积

### 常见复杂度分析

#### O(1)

#### O(logn)、O(nlogn)

O(logn)是以 2 为底的对数

什么情况下会出现 O(logn)

```js
i = 1;
while (i <= n) {
  i = i * 2;
}
```

上面的代码什么时候退出循环？当 2^x > n 时退出，等式两边取对数，得 logn
由于对数可以转换：log3^n 就等于 log3^2 _ log2n = 常数 _ log2n = logn

O(nlogn) 也是一种非常常见的算法时间复杂度。比如，归并排序、快速排序的时间复杂度都是 O(nlogn)

#### O(m+n)、O(m\*n)

### 4 种不同的复杂度分析

同一段代码，在不同输入（n 不一定取到无穷大）的情况下，复杂度量级有可能是不一样的。
为了表示代码在不同情况下的不同时间复杂度，我们需要引入三个概念：最好情况时间复杂度、最坏情况时间复杂度和平均情况时间复杂度

#### 最好、最坏情况时间复杂度

最好情况时间复杂度就是，在最理想的情况下，执行这段代码的时间复杂度。
最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度。

#### 平均时间复杂度

实际上，在大多数情况下，我们并不需要区分最好、最坏、平均情况时间复杂度三种情况。很多时候，我们使用一个复杂度就可以满足需求了。只有同一块代码在不同的情况下，时间复杂度有量级的差距，我们才会使用这三种复杂度表示法来区分

#### 均摊时间复杂度

平均复杂度只在某些特殊情况下才会用到，而均摊时间复杂度应用的场景比它更加特殊、更加有限。

什么情况会用到均摊时间复杂度：

对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上。而且，在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度。

```c

// 全局变量，大小为10的数组array，长度len，下标i。
int array[] = new int[10];
int len = 10;
int i = 0;

// 往数组中添加一个元素
void add(int element) {
   if (i >= len) { // 数组空间不够了
     // 重新申请一个2倍大小的数组空间
     int new_array[] = new int[len*2];
     // 把原来array数组中的数据依次copy到new_array
     for (int j = 0; j < len; ++j) {
       new_array[j] = array[j];
     }
     // new_array复制给array，array现在大小就是2倍len了
     array = new_array;
     len = 2 * len;
   }
   // 将element放到下标为i的位置，下标i加一
   array[i] = element;
   ++i;
}
```
